{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you are using Google Colab, please, note following steps:\n",
    "0. Setup colab GPU in two clicks:\n",
    "\n",
    " 0.1 In `Edit` click on `Notebook settings`\n",
    " \n",
    " ![](./colab_gpu_1.png)\n",
    "\n",
    " 0.2 Choose GPU in Hardware accelerator\n",
    " \n",
    " ![](./colab_gpu_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "sns.set()\n",
    "\n",
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you don't use Colab and/or don't have GPU, then change `cuda:0` to `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bit more steps to setup Google Colab\n",
    "\n",
    "1. Open this link: https://drive.google.com/drive/folders/1-diBeyX4vho70KtYUZbXxNcy3eRzrXL0?usp=sharing\n",
    "\n",
    "2. Add it to your Drive:\n",
    "![](http://www.digitalchaoscontrol.com/wp-content/uploads/2016/10/AddtoMyDrive.jpg)\n",
    "\n",
    "3. Uncomment and run following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pathes\n",
    "\n",
    "If you are using Google colab left it as it is. \n",
    "\n",
    "Otherwise, if you are running notebook locally, change pathes accordinly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/gdrive/My Drive/mlhep2019/data_train.npz'\n",
    "val_data_path = '/gdrive/My Drive/mlhep2019/data_val.npz'\n",
    "test_data_path = '/gdrive/My Drive/mlhep2019/data_test.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
    "\n",
    "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
    "\n",
    "File `dat_train.npz` contains four arrays: \n",
    "\n",
    "  * `EnergyDeposit` - images of calorimeters responses\n",
    "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
    "  * `ParticlePoint` - $x, y$ of initial particle\n",
    "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train dataset\n",
    "data_real = np.load(train_data_path, allow_pickle=True)\n",
    "print(list(data_real.keys()))\n",
    "\n",
    "# [data_size, 900]\n",
    "EnergyDeposit = data_real['EnergyDeposit']\n",
    "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
    "# channels are needed for pytorch conv2d-layers\n",
    "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
    "\n",
    "# [data_size, 3]\n",
    "ParticleMomentum = data_real['ParticleMomentum']\n",
    "\n",
    "# [data_size, 2]\n",
    "ParticlePoint = data_real['ParticlePoint']\n",
    "\n",
    "# [data_size, 1]\n",
    "ParticlePDG = data_real['ParticlePDG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('$p_x$-$p_y$ distribution')\n",
    "plt.scatter(ParticleMomentum[:, 0], ParticleMomentum[:, 1]);\n",
    "plt.xlabel('$p_x$')\n",
    "plt.ylabel('$y_x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('$x$-$y$ distribution')\n",
    "plt.scatter(ParticlePoint[:, 0], ParticlePoint[:, 1]);\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 3, figsize=(12, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    axs[i // 3][i % 3].imshow(EnergyDeposit[i, 0])\n",
    "plt.title('Examples of calorimeter response')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 3, figsize=(12, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    axs[i // 3][i % 3].imshow(np.log(1 + EnergyDeposit[i, 0]))\n",
    "plt.title('Examples of log-calorimeter response')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not actully interested in p_z momentum\n",
    "ParticleMomentum = ParticleMomentum[:, :2]\n",
    "ParticlePoint = ParticlePoint[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading it to pytorch `DataLoader`\n",
    "\n",
    "  1. Convert from `numpy`-array to Torch `tensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
    "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
    "ParticlePoint = torch.tensor(ParticlePoint).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. Convert three `tensors` to `TensorDataset`-format\n",
    "  3. Wrapping it with `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
    "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, \n",
    "                                              batch_size=BATCH_SIZE, \n",
    "                                              pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our neural network regressor\n",
    "\n",
    "![title](https://stackmorelayers.be/bg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 512) \n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 2 + 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
    "        x = x.view(len(x), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Regressor().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "opt = optim.Adam(regressor.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative MSE that is used in competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change\n",
    "ParticleMomentum_mean, ParticlePoint_mean = ParticleMomentum.mean(dim=0), ParticlePoint.mean(dim=0)\n",
    "ParticleMomentum_ParticlePoint_mean = torch.cat([ParticleMomentum_mean, ParticlePoint_mean]).to(device)\n",
    "\n",
    "def metric_relative_mse(y_true, y_pred):\n",
    "    return ((y_true - y_pred).pow(2).mean(dim=0) / (y_true - ParticleMomentum_ParticlePoint_mean).pow(2).mean(dim=0)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "In this example we are using `L1Loss`. \n",
    "\n",
    "But maybe it's better to stick to another loss?.. `MSE` or `log-cosh`?.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(epochs=100):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "    # init running average\n",
    "    loss_meter = RunningAverageMeter(momentum=0.99)\n",
    "    metric_meter = RunningAverageMeter(momentum=0.99)\n",
    "    # iterating over epochs...\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # ...and over batches\n",
    "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
    "            # moving them to device(for example, cuda-device)\n",
    "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
    "                                                                   ParticleMomentum_b.to(device), \\\n",
    "                                                                   ParticlePoint_b.to(device)\n",
    "            \n",
    "            # predicting an array of size [batch_size, 4]\n",
    "            pred = regressor(EnergyDeposit_b)\n",
    "\n",
    "            # calc loss function\n",
    "            loss = loss_fn(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1))\n",
    "\n",
    "            # manually zeroing gradients from previous step\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # and calculating new gradients based on value of loss function\n",
    "            loss.backward()\n",
    "            \n",
    "            # updating weights\n",
    "            opt.step()\n",
    "            \n",
    "            # storing metrics for vizualization\n",
    "            loss_meter.update(loss.item())\n",
    "            metric_meter.update(metric_relative_mse(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1)).item())\n",
    "            losses.append(loss_meter.avg)\n",
    "            metrics.append(metric_meter.avg)\n",
    "\n",
    "        # plot loss and our metric\n",
    "        clear_output()\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.plot(losses, label='Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.plot(metrics, label='Metric')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 10 epoch enought?\n",
    "run_training(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for validation set\n",
    "\n",
    "In `data_val.npz` and `data_test.npz` you only have one key: `EnergyDeposit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation data\n",
    "data_val = np.load(val_data_path, allow_pickle=True)\n",
    "EnergyDeposit_val = data_val['EnergyDeposit']\n",
    "EnergyDeposit_val = EnergyDeposit_val.reshape(-1, 1, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting [data_num, 4] array with px, py, x, y\n",
    "prediction_val = regressor.cpu()(torch.tensor(EnergyDeposit_val).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
    "ParticleMomentum_val, ParticlePoint_val = prediction_val.detach().numpy()[:, :2], prediction_val.detach().numpy()[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predictions in .npz format\n",
    "np.savez_compressed(test_data_path, \n",
    "                    ParticlePoint=ParticlePoint_val, \n",
    "                    ParticleMomentum=ParticleMomentum_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "data_test = np.load(test_data_path, allow_pickle=True)\n",
    "EnergyDeposit_test = data_test['EnergyDeposit']\n",
    "EnergyDeposit_test = EnergyDeposit_test.reshape(-1, 1, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting [data_num, 4] array with px, py, x, y\n",
    "prediction_test = regressor.cpu()(torch.tensor(EnergyDeposit_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting ParticleMomentum and ParticlePoint in two arrays\n",
    "ParticleMomentum_test, ParticlePoint_test = prediction_test.detach().numpy()[:, :2], prediction_test.detach().numpy()[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predictions in .npz format\n",
    "np.savez_compressed('data_test_prediction.npz', \n",
    "                    ParticlePoint=ParticlePoint_test, \n",
    "                    ParticleMomentum=ParticleMomentum_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `zip-zip` files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('./solution.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Google Colab you might not be able to download you solution from browser. Then you can download it from left sidebar of Colab:\n",
    "\n",
    "![](./colab_download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome, you are breathtaking!\n",
    "\n",
    "![](https://i.kym-cdn.com/entries/icons/original/000/030/029/cover2.jpg)\n",
    "\n",
    "Now you can send it to codalab :)\n",
    "\n",
    "If you forgot where it is: http://codalab.coresearch.club/competitions/70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future steps:\n",
    "\n",
    "1. Tune arcitecture \n",
    "  * stack moar layers :)\n",
    "  * different types on nonlinearities, hyperparameters of `Conv2d`-layer, initializations, etc...\n",
    "  * dropout & other regularizations\n",
    "  \n",
    "  \n",
    "2. Play with optimization procedure\n",
    "  * train for more epochs\n",
    "  * maybe looking at train metricis is not the best way to prevent overfitting :)\n",
    "  * learning rate scheduler\n",
    "  * early stopping\n",
    "  * different types of loss functions: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "  * SWA: https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/\n",
    "  \n",
    "  \n",
    "3. data augmentation\n",
    "  * rotate & shift images(do not forget to transform $p_x, p_y$, $x, y$ as well!)\n",
    "  * adding nose to images/target variables\n",
    "  \n",
    "  \n",
    "4. other trick\n",
    "  * train to predict $p_z$ and particle type: multi-task or/and transfer learning( http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_15_multi_task_learning.pdf )\n",
    "  * normalization of input/output data: Box-Cox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
